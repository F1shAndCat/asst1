# T1

## 1

OK.The Code is in the F1shAndCat branch

## 2

$x$ is the Threads count .

$f(x)=\frac{cx}{ax^2+cx+b}=\frac{x}{a^{'}x^2+x+b^{'}}$

$cx$ is the boosting factor when $ax^2+b$ is the switchings between threads' factor since we ignore the joining time waste because the Threads' expected running time is the same.

The function actually comes from a conjugation that the accelerate rate will increase first and decreases last.Thus this is maybe a inverse Hook function.

![1685983719878](image/T1/1685983719878.png)$f(x)=1+\frac{800*x}{x^2+1296}$

Not Linear.The acceleration depends on the difference between the bus rate and the processing code's clock counts.So when there are sufficiently many threads,the pipelining will be diffused and it may get slower due to the thread managing.

Futhurmore,we noticed that the 2-pows sometimes runs better than the ones with more Threads but not in 2-pows pattern.Guess that this is because the blocks are not attributed evenly in each threads regarding the flooring division ,or because the processors' structure is built in 2 pows.

# (UPD)3.

* 2Threads:(1.95x speedup from 2 threads)
* 3Threads:(1.64x speedup from 3 threads)
* 4Threads:(2.37x speedup from 4 threads)
* 5Threads:(2.49x speedup from 5 threads)
* 6Threads:(3.22x speedup from 6 threads)
* 7Threads:(3.39x speedup from 7 threads)
* 8Threads:(4.00x speedup from 8 threads)
* 16Threads:(7.19x speedup from 16 threads)
* 32Threads:(10.72x speedup from 32 threads)

  * Discovered changing little after switching to the given method

# 4

Attribute blocks based on columns dividing for each Thread to process to obtain speedup,while omiting the mutiplication code since it can be substituded by addition with fewer clock cycles consumed.

# 5

As above in #3,16 threads has 7.19x speedup performance.It DOES have a noticably greater performance than that of 8 threads.This is because for my PC's CPU is AMD Ryzen 7 4800H which has  8 cores,with hyper-threads it has 16 threads, thus it runs well in 16threads,and even in 32 threads because the thread managing cost is less than the pipling speedup.(BTW,The speedup rate congverges to 11x at 64 threads, with about 10.8x speedup)

# EXTRA

I've been trapped by the float number for a long time because I've been trying to imple my own Thread Version, changing all the multiplication in thread to addition due to waiting times. I've conjectured that the float error may be big.But I'd just found another problem,that i used interger dividing  and float dividing at the same time,which will leads to a distortion though we can barely tell.That's why i continued to find the next version.I changed all dividing to interfer dividing and United the Steplength to make each number be at a same standard and it will definitely has no distortion. But it still didn't follow the Serial Method. Finally I changed my addition to multiplication ,and the iterations at the bright-dark border diverge from the former significantly.(From 256 to 50!)Now it turns out obviously that it's due to the FloatError.

Had no choice but impled the Given Method,and it works at place.The speedup also change little.this is really annoying. Maybe the pipeling diffused the latency? Trying to optimize a thing that maybe already fully optimized,that's what we often do.But when our investment pays,it satisfy me.
