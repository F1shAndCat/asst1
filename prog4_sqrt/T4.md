# T4

## 1

SIMD speedup is about 5x.

multi-core parallelization speedup is about 10x.

## 2

Making all the elements' calculation in vector more complicated will increase the SIMD effciency.

Making each function's processing time longer,namely the Iterations until convergence  will increase the degree SIMD's efficiency increases.

Thus let all the elements in the array to be 2.999(not 3 because 3 will not converge),this will make the SIMD speedup come to about 7.2x,and total speedup at about 75x.

This doesn't increase multi-core parallelization speedup since the calculating instructions aren't changed.So there's no difference in the pipeling efficency ,thus multi-core parallelization speedup stays the same.

## 3

Against .2,there're enough reasons for us to choose a number that mimize the calculation complexity. Constuct all 1's satisfy the condition.

the relative performance is about 1.5x.because the cauculation will barely cost time.So the complexity will come mainly from the iteration and condition

clause ,which vectorization will do little help.

## 4

Done.Added it to the excutables and the source code.

there's a trivial but usal buffle that the absolute of float number is different from that of intergers.That sounds obvious but I'd been trapped here for a long time.

You should just bitand is highest bit to zero.That's enough,despite for interger when it's negative we should also flip other bits and plus 1.(also can be treated as module 2^32/64 subtraction,but that comes more directly).
